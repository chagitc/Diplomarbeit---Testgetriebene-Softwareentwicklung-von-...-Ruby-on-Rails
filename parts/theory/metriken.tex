\section{Code-Metriken}
Eine Codemetrik ist eine Maßzahl, die zum Vergleich dient und ein Qualitätsmerkmal für ein Stück Code oder ein Programm darstellt. Sie ist wird den Software-Metriken und Produkt-Metriken zugeordnet.

\epigraph{A function whose inputs are software data and whose output is a single
numerical value that can be interpreted as the degree to which software possesses a given attribute that affects its quality}{\cite{ieee_1998}}

Dem Verwenden von Code-Metriken liegt der Wunsch zugrunde, komplexe Codeteile auf einfache Zahlen automatisiert beurteilen zu lassen, um potenziell suboptimale Codestellen schnell zu finden, welche möglicherweise in Zukunft Defekte verursachen könnten. Aus Business-Sicht stellen Code-Metriken auch eine Methode dar, Entwicklungsfortschritt zu messen und zu beurteilen.
\subsection{Überblick über Code-Metriken und Skalen}
Hier seien nun einige der geläufigsten Code-Metriken vorgestellt.
\paragraph{Lines of Code (LOC)} ist eine häufig verwendete, und die am leichtesten zu bestimmende Größe. Sie repräsentiert den Umfang eines Programmes. Es werden alle Zeilen einer Datei gezählt, die nicht leer und keine Kommentare sind. Kommentare wiederrum können als eigene Metrik verwendet werden, um den Grad der Quelltextdokumentation zu bestimmen.

Diese Größe erhält eine größere Aussage, wenn man sie ins Verhältnis z.B. der Klasse oder eines Codefiles setzt. So kann man mit "`LOC / Klasse"' schon diejenigen Klassen finden, die wahrscheinlich zu komplex sind. \\

\paragraph{Zyklomatische Komplexität} ist ein Indikator für die Komplexität auf Basis des Kontrollflussgraphen eines Programms. Gemessen wird die Anzahl der linear unabhängigen Programmpfade. Sie ist für einen Graphen definiert durch:

\shadebox{
  $$    M = E - N + 2P $$
  \begin{center}
\begin{tabular}{ll}
   E & Anzahl der Kanten \\
   N & Anzahl der Knoten  \\
   P & Anzahl der verbundenen Komponenten \\
  \end{tabular}  \end{center}

}

In einem normalen Programm ist die Zyklomatische Komplexität die Anzahl der Entscheidungspunkte + 1 \citep[S. 314]{mccabe_complexity_1976}.

Ein daraus abgeleitetes Testverfahren "`Basis Path Testing"' schlägt vor, dass die Anzahl der Tests mindestens genauso groß sein sollte, wie die Grad der Komplexität \citep[S. 318]{mccabe_complexity_1976}. Dadurch erreicht man Branch-Coverage (C1) (Mehr zu Testabdeckung im nächsten Unterabschnitt).

\paragraph{Anzahl Bad Smells} ist eine aggregierte Metrik über Anzahl und Vorkommen von suboptimale Codestellen (\glossarpl{smell}). Diese Code-Smells sind meist ein oberflächliches Symptom für ein möglicherweise tieferliegendes Designproblem. Ob ein konkreter Smell relevant ist, muss im Einzelfall entschieden werden. Für eine grobe Übersicht genügt aber z.B. auch einfach die Summe, oder die Anzahl der Codesmells relativ zur Codemenge (Smells pro Tausend LOC). Welche Bad Smells für die Entwicklung entscheidend sind hängt von der gewählten Sprache, dem damit einhergehenden Programmierparadigma und manchmal auch den verwendeten Frameworks. Einige für Ruby relevante Smells sind z.B. (Nach \citep{kevin_rutherford_code_2010}):

\begin{description}
 \item[Geringe Kohäsion] Ist ein Oberbegriff für verschiedene andere Smells anzuwenden bei objektorientierten Programmen. Einer davon ist z.B.. "`Feature Envy"' (deutsch: Neid). Eine Klasse weiß zuviel über die internen Strukturen einer anderen Klasse, und implementiert Funktionalität, die eigentlich in jene Klasse gehören sollten. \\
 Im Beispiel würde die Berechnung eines Gesamtpreises z.B. in die Klasse \texttt{Checkout} gehören.
 \begin{lstlisting}
    @checkout.total = @checkout.total_price * MWST
 \end{lstlisting}
 \item[Nichtssagender Name] gilt für alle Programmiersprachen. Falls Bezeichner weniger als 3 Zeichen lang sind, oder Funktionen den Namen "`do"' oder "`run"' haben. Ausnahmen könnte man z.B. für die Schleifenvariable $i$ rechtfertigen
 \item[Gesetz von Demeter] bzw. die Verletzung desselben. Objekte sollten nur mit den Objekten in ihren unmittelbaren Nähe kommunizieren, und nicht etwa in Nachrichtenketten, wie z.B.:
 \begin{lstlisting}
  @job.user.address.street
 \end{lstlisting}
 Beim Law of Demeter ist eine solche Kette bis maximal Länge 1 erlaubt.
 \item[Duplikation] Offensichtliche Ähnlichkeiten zwischen Programmstücken (oder sogar Deckungsgleichheit bei Anwendung von Copy \& Paste). Fortgeschrittene Analysemethoden betrachten den Abstrakten Syntaxbaum, und können so strukturelle Ähnlichkeiten feststellen
 \end{description}

Diese Smells können mit dem Tool reek\footnote{\url{https://github.com/kevinrutherford/reek/wiki/Code-Smells}} festgestellt werden.
Weitere Informationen zu Smells und deren Beseitigung finden sie in dem Buch "`Refactoring"' von M. Fowler \citep{fowler_refactoring_1999}.

\subsection{Code-Metriken für Tests}
\label{sec:metrics}
Tests haben (auch) die Aufgabe, ein Programm oder Codestück auf Korrektheit zu untersuchen. Die Tests allerdings haben ihrerseits i.d.R. keine Tests. Um also die Nützlichkeit der eigenen Tests zu bestimmen, kann man sich aber zumindest auf Code-Metriken stützen.
Tests sind in erster Linie natürlich auch Code und können mit den oben genannten Metriken beurteilt werden. Zudem gibt es aber einige weitere exklusive Methoden, Qualität von Tests zu messen. 

\subsubsection{Verhältnis von Lines of Test zu Lines of Code}
Neben den Lines of Code kann auf dieselbe Weise die Anzahl der Codezeilen der Testklassen ermittelt werden. Daraus ermittelt sich das Verhältnis:

\shadebox{
  $$    R = \frac{\text{Lines of Code}}{\text{Lines of Test}}$$
  \begin{center}
\begin{tabular}{ll}

   $R \ll 1$ & \small Falls es deutlich weniger Testzeile (LoT), als Codezeilen (LoC) geben sollte\\
	     & \small so ist dies ein Indiz für zu wenige Tests\\
   $R > 1$   &\small Eine große Anzahl an Tests ist zwar wünschenswert, aber dies macht\\
	      & \small keine Aussage über den Vollständigkeit oder die Qualität der Tests   
  \end{tabular}  \end{center}

}

Sollte dieser deutlich kleiner als 1 sein, so ist dies ein Symptom für zu wenige Tests. Diese Zahl ist von dem Testframework und dem Programmframework stark abhängig. Gute Projekte sollten mehr Test-Code, als Programmcode besitzen, um so die Zahl der Defekte gegen 0 zu reduzieren \citep{hunt_pragmatic_1999}[S. 238]. 
        
\subsubsection{Testausführungsabdeckung}
Die Testabdeckung, misst den Grad inwieweit ein Programm getestet wurde. Die Angabe erfolgt in Prozent, wobei 100\% bedeuten, "`das Programm wurde durch die Tests komplett ausgeführt"', und 0\% "`Das Programm wurde durch die Tests überhaupt nicht berührt"' Dabei wird die vorhandene Test-Suite ausgeführt und währenddessen der entsprechende Quellcode beobachtet. Es wird festgehalten, welche Anweisungen ausgeführt wurden. Allerdings gibt es 3 Abstufungen, diese Abdeckung zu beobachten (Mit steigender Komplexität des Messverfahrens):
\begin{description}
 \item[C0] (Anweisungsüberdeckung, Statement Coverage) ist die am einfachsten zu bestimmende Abdeckung. Dabei wird geprüft, ob jede Zeile des Quellcodes während der Codeausführung mindestens einmal ausgeführt wurde
 \item[C1] (Zweigüberdeckung, Branch Coverage) prüft zusätzlich, ob jeder Zweig jeder Zeile ausgeführt wurde. Dies ist wichtig,falls man ternäre Ausdrücke\footnote{if-then-else in einer Zeile: int a = (1==1) ? 5 : 3} verwendet
 \item[C2] (Pfadüberdeckung, Path Coverage) prüft, ob jeder mögliche Codepfad durchlaufen wurde. Ein Codepfad sei eine einmalige Abfolge von Zweigen innerhalb einer Funktion von Eintritt bis Rücksprung \citep{steve_cornett_code_1996}. So werden z.B. bei 10 Bedingungen 1024 Pfade generiert, denen bei einer 100\% Abdeckung auch 1024 Tests entgegenstehen müssten.
 \end{description}
 Anmerkung: In der Literatur startet in einigen Fällen die Nummerierung bei C0 \citep{catherine_powell_abakas_2008}, in anderen Fällen aber bei C1 \citep{steve_cornett_code_1996}.
 
 Für Ruby 1.8.7 gibt es das Tool rcov \footnote{\url{http://relevance.github.com/rcov/}}, für Ruby ab 1.9.1 simple-cov\footnote{\url{https://github.com/colszowka/simplecov}}, welche beide die C0 Testabdeckung bestimmen können. Zum aktuellen Zeitpunkt sind keine weiteren Tools bekannt, um C1 oder C2 Abdeckungen zu bestimmen.
 \paragraph{Wieviel Testabdeckung ist sinnvoll oder notwendig}
 
 Beim Messen der Abdeckung stellt man sich schnell die Frage, wieviel Testabdeckung notwendig ist. Zuerst sei die Art des Messverfahrens, also C0 bis C2, wichtig. je komplexer das Messen erfolgte, desto geringer kann also die Testabdeckung am Ende ausfallen \citep{catherine_powell_abakas_2008}.
 
 Falls dem TDD-Prozess minutiös gefolgt wurde, so ist die C0 Testabdeckung immer 100\% \citep{beck_test_2002}. Für ein Rails Projekt sei es auch relativ leicht, 100\% oder nahe 100\% zu erreichen \citep{rappin_rails_2011}. Die Zahl "`100\%"' sei für sich genommen nutzlos, aber sie zu erreichen, sei für den Prozess der Testgetriebenen Entwicklung nützlich \citep[S. 270]{rappin_rails_2011}. Vielen Autoren bringen aber zum Ausdruck, dass es von der Situation abhängt \citep{infoq_2007} wieviel Testabdeckung sinnvoll ist. Test-Anfänger sollten sich zuerst überhaupt ans Testen gewöhnen, und erfahrene Entwickler sollte wissen, dass es keine einzige einfache Antwort auf diese Frage gebe \citep{infoq_2007}. Zudem gebe eine hohe Abdeckung keinen Aufschluss darüber, dass gut getestet wurde. Aber eine niedrige Zahl zeigt deutlich auf Missstände hin. Einem pragmatischen Ansatz von \citeauthor{alberto_savoia_code_2007} folgend, kann man aus dem Verhältnis der Zyklomatischen Komplexität mit der Testabdeckung eines Codestückes suboptimale Teile finden. Je mehr Verzweigung eine Methode hat, desto höher sollte ihre Testabdeckung sein \citep{alberto_savoia_code_2007}. In einem Artikel empfiehlt \citeauthor*{steve_cornett_code_1996} eine Liste von Zielen, die es je nach Budget und Zeit zu erreichen gilt, beginnend damit, dass mindestens eine Funktion in 90\% der Quelltextdateien durch die Tests aufgerufen wird bis zum finalen Schritt einer 100\% Zweiüberdeckungs-Testabdeckung \citep{steve_cornett_code_1996}.
 
 Zusammenfassend kann man sagen, dass es keine eindeutige Antwort gibt. Eine niedrige C0 Abdeckung von 50\% oder weniger zeigt allerdings deutliche Missstände beim Testverfahren an.
 
 \subsubsection{Mutations/Pertubationstests -- Defect insertion}
 \label{sec:mutation}
 Eine weitere Methode, um die Qualität von Testcode zu messen, ist der Mutationstest. Dies ist ein diversifizierendes, fehlerbasiertes Testverfahren \citep{liggesmeyer_modultest_1990}. Hierbei werden (automatisiert oder manuell) nacheinander alle Zeilen des Programmcodes geändert, und geprüft, ob danach ein Test fehlschlägt \citep{beck_test_2002}.
 
 Für Ruby gibt es ein Werkzeug, "`Heckle"`\footnote{\url{http://ruby.sadi.st/Heckle.html}}, welches dieses Verfahren implementiert. Im Detail werden Bedingungen negiert, konstante Zahlen und Funktionsaufrufe verändert, Zuweisungen verändert usw. \citep{ruby_sadists_confessions_2010}. Dabei wird immer eine Änderung (Mutation) vorgenommen, und dann alle Tests ausgeführt. Sollten dennoch in einer Mutation kein Test fehlschlagen, dass ein Test fehle, so ist die Annahme des Testverfahrens.
 
 Um hieraus eine Metrik zu gewinnen, können die Anzahl der Mutationen gemessen werden, bei denen der Test nicht fehlschlug.  
 \subsection{Notwendigkeit von Code Metriken}
 
 Code-Metriken geben dem Programmierer automatisiert und schnell ein Feedback über die Qualität seiner Arbeit. Sie helfen dabei, Probleme frühzeitig zu erkennen und die Wartbarkeit durch gezielte Refaktorisierungen nachhaltig zu verbessern. Auch psychlogische Auswirkungen dürfen nicht unterschätzt werden. Alleine der Fakt, dass Codemetriken in einem Unternehmen regelmäßig verwendet werden, motiviert den Programmierer keinen sogenannten "`Big Ball of Mud"'\footnote{Ein Antipattern, in dem ein System keinerlei offensichtliche Architektur zu haben scheint} zu schreiben. Insbesondere in kleinen Projektteams, die keine dedizierte Qualitätssicherung haben, sind Codemetriken als kostengünstiges Kontrollinstrument unerlässlich. Studien zeigen, dass der konsequente Einsatz von Code-Metriken und Analysebenchmarks die Fehlerdichte und Entwicklungskosten stark verringen kann \citep[S.10f]{baggen_standardized_2011}.
 
 Für die Testgetriebene Software dient insbesondere in der Anfangsphase die Testabdeckung als Kontrollinstrument, um zu prüfen, ob der TDD-Prozess korrekt umgesetzt wird \citep[S. 300]{nagappan_realizing_2008}. Außerdem sollte der zeitliche Verlauf der Metriken beobachtet werden, um Trends abzuschätzen und frühzeitig gegensteuern zu können. Für in \glossar{TDD} erfahrene Programmierer mag die Beobachtung der Testabdeckung nicht notwendig sein, für Einsteiger allerdings eine effektive Kontrollmöglichkeit.
 
 Nach Erfahrungen in der pludoni GmbH sind Code-Metriken ein wichtiges Feedbackinstrument, und unterstützen damit das Schreiben sauberen Codes. Wichtig ist, dass die Metriken regelmäßig berechnet werden, entweder als Cronjob oder nach jedem Einchecken in den Hauptentwicklungszweig der Versionsverwaltung, und in regelmäßigen Abständen von den Programmierern und Team-Leiter gelesen und besprochen werden. Allerdings besteht bei einer zu hohen Beobachtung der Metriken die Gefahr, eines Hawthorne-Effektes, d.h. dass die unter Beobachtung stehenden Programmierer ihr Verhalten den Code-Metriken anpassen, um optimale Ergebnisse zu erhalten \citep[52. Karte]{langr_agile_2011}, und so nur eine scheinbare Verbesserung erzielen würden.
